{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/mnt/teams/TM_Lab/Arjun Bhaskaran/Social interaction project/videos/'\n",
    "processed_data_path = 'successful_trials_by_day'\n",
    "reference_path = ['marker_reference/' + dir for dir in os.listdir('marker_reference')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_time_string(time_string):\n",
    "    time_string = str(time_string)\n",
    "    if time_string == 'nan':\n",
    "        return None\n",
    "    if len(time_string) > 14:\n",
    "        millis = float(time_string[14:])\n",
    "    else:\n",
    "        millis = 0\n",
    "    secs = int(time_string[12:14])\n",
    "    mins = int(time_string[10:12])\n",
    "    hours = int(time_string[8:10])\n",
    "    day = int(time_string[6:8])\n",
    "    month = int(time_string[4:6])\n",
    "    year = int(time_string[0:4])\n",
    "    # divide millis until there is nothing to the right of the decimal point\n",
    "    while millis > 1:\n",
    "        millis /= 10\n",
    "    return datetime.datetime(year, month, day, hours, mins, secs, int(millis * 1000))\n",
    "\n",
    "\n",
    "# Using OpenCV, takes a reference image of the interaction area and the current frame\n",
    "# using the reference image finds a perspective transform to transform and crop the current frame to the reference frame using SIFT algorithm\n",
    "def find_area_and_transform(frame, reference):\n",
    "    # create SIFT object\n",
    "    sift = cv2.SIFT_create()\n",
    "    # find keypoints and descriptors for reference and current frame\n",
    "    kp1, des1 = sift.detectAndCompute(reference,None)\n",
    "    kp2, des2 = sift.detectAndCompute(frame,None)\n",
    "    # create BFMatcher object\n",
    "    matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_FLANNBASED)\n",
    "    knn_matches = matcher.knnMatch(des1, des2, 2)\n",
    "    good = []\n",
    "    for m,n in knn_matches:\n",
    "        if m.distance < 0.75*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    #-- Localize the object\n",
    "    obj = np.empty((len(good),2), dtype=np.float32)\n",
    "    scene = np.empty((len(good),2), dtype=np.float32)\n",
    "    for i in range(len(good)):\n",
    "        #-- Get the keypoints from the good matches\n",
    "        obj[i,0] = kp1[good[i].queryIdx].pt[0]\n",
    "        obj[i,1] = kp1[good[i].queryIdx].pt[1]\n",
    "        scene[i,0] = kp2[good[i].trainIdx].pt[0]\n",
    "        scene[i,1] = kp2[good[i].trainIdx].pt[1]\n",
    "    # find the perspective transform\n",
    "    try:\n",
    "        M, mask = cv2.findHomography(scene, obj, cv2.RANSAC,5.0)\n",
    "        return M, len(good)\n",
    "    except:\n",
    "        return None, 0\n",
    "\n",
    "\n",
    "def scrub_video_seconds(vid_capture, seconds):\n",
    "    fps = vid_capture.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(vid_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    current_pos_seconds = frame_count / fps\n",
    "    time_to_skip = current_pos_seconds - seconds\n",
    "    for i in range(int(time_to_skip * fps)):\n",
    "        vid_capture.read()\n",
    "    return vid_capture\n",
    "\n",
    "# iterate through list of paths and get the best matching SIFT transformation\n",
    "def find_matching_transformation(scene , paths):\n",
    "    references_images = [cv2.imread(path) for path in paths]\n",
    "    transformations = []\n",
    "    num_matches = []\n",
    "    for reference in references_images:\n",
    "        transformation, num_match = find_area_and_transform(scene, reference)\n",
    "        transformations.append(transformation)\n",
    "        num_matches.append(num_match)\n",
    "    return transformations[num_matches.index(max(num_matches))], max(num_matches)\n",
    "\n",
    "def show_successfull_trials(video, df, offset):\n",
    "     # iterate through df and for each successfull trial get the start time in seconds\n",
    "    reference_image = cv2.imread(reference_path[0])\n",
    "    transformation, num_match = find_matching_transformation(video.read()[1], reference_path)\n",
    "    for index, row in df.iterrows():\n",
    "        if row['successful_trials']:\n",
    "            transformation_new, num_match_new = find_matching_transformation(video.read()[1], reference_path)\n",
    "            if num_match_new > num_match or num_match_new > 30:\n",
    "                transformation = transformation_new\n",
    "                num_match = num_match_new\n",
    "            start_time_str = row['time_since_start'].split(' ')[2]\n",
    "            start_time = start_time_str.split(':')\n",
    "            start_time = float(start_time[0])*3600 + float(start_time[1])*60 + float(start_time[2]) + offset\n",
    "            end_time = start_time + 15\n",
    "            # set the video to the start time\n",
    "            fps = video.get(cv2.CAP_PROP_FPS)\n",
    "            current_time = float(video.get(cv2.CAP_PROP_POS_FRAMES)) / fps\n",
    "            time_offset = start_time - current_time\n",
    "            for i in range(int(time_offset * video.get(cv2.CAP_PROP_FPS))):\n",
    "                video.read()\n",
    "\n",
    "            # find the frames where mouse R and L break the beam\n",
    "            R_time_offset = row['R']\n",
    "            L_time_offset = row['L']\n",
    "            \n",
    "            # find the mice names\n",
    "            name1 = row['names'][:2]\n",
    "            name2 = row['names'][2:]\n",
    "            # display the video until the end time\n",
    "            \n",
    "            while True:\n",
    "                success, image = video.read()\n",
    "                if success == False or float(video.get(cv2.CAP_PROP_POS_FRAMES))/fps > end_time:\n",
    "                    break\n",
    "                # add a countdown to the video \n",
    "                time_since_start_seconds = float(video.get(cv2.CAP_PROP_POS_FRAMES))/fps\n",
    "                time_since_start = str(datetime.timedelta(seconds=time_since_start_seconds))\n",
    "                transformed = cv2.warpPerspective(image, transformation, (reference_image.shape[1], reference_image.shape[0]))\n",
    "\n",
    "                cv2.putText(image, start_time_str + ' ' + time_since_start, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                # display the mice names\n",
    "                cv2.putText(image, 'trial: ' + str(index), (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                cv2.putText(image, name1 + ' ' + name2, (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                cv2.putText(image, str(df['cue_times'])[:18], (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                cv2.imshow('frame', image)\n",
    "                cv2.imshow('transformed', transformed)\n",
    "\n",
    "                if cv2.waitKey(12) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "def write_successful_trials(video, df, offset, path):\n",
    "    # iterate through df and for each successfull trial get the start time in seconds\n",
    "    reference_image = cv2.imread(reference_path[0])\n",
    "    transformation, num_match = find_matching_transformation(video.read()[1], reference_path)\n",
    "    # create video writer\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    for index, row in df.iterrows():\n",
    "        if row['successful_trials']:\n",
    "            transformation_new, num_match_new = find_matching_transformation(video.read()[1], reference_path)\n",
    "            if num_match_new > num_match or num_match_new > 30:\n",
    "                transformation = transformation_new\n",
    "                num_match = num_match_new\n",
    "            start_time_str = row['time_since_start'].split(' ')[2]\n",
    "            start_time = start_time_str.split(':')\n",
    "            start_time = float(start_time[0])*3600 + float(start_time[1])*60 + float(start_time[2]) + offset\n",
    "            end_time = start_time + 15\n",
    "            # set the video to the start time\n",
    "            fps = video.get(cv2.CAP_PROP_FPS)\n",
    "            current_time = float(video.get(cv2.CAP_PROP_POS_FRAMES)) / fps\n",
    "            time_offset = start_time - current_time\n",
    "            for i in range(int(time_offset * video.get(cv2.CAP_PROP_FPS))):\n",
    "                video.read()\n",
    "\n",
    "            # find the mice names\n",
    "            name1 = row['names'][:2]\n",
    "            name2 = row['names'][2:]\n",
    "            # write the video to a new file until the end time\n",
    "            # check if folder exists, if not create it\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            out = cv2.VideoWriter(path + '_trial_' +str(index) + '.mp4', fourcc, fps, (reference_image.shape[1], reference_image.shape[0]))\n",
    "\n",
    "            while True:\n",
    "                success, image = video.read()\n",
    "                if success == False or float(video.get(cv2.CAP_PROP_POS_FRAMES))/fps > end_time:\n",
    "                    break\n",
    "                # add a countdown to the video \n",
    "                transformed = cv2.warpPerspective(image, transformation, (reference_image.shape[1], reference_image.shape[0]))\n",
    "                out.write(transformed)\n",
    "                if cv2.waitKey(12) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of video names from the folder of processed CSVs\n",
    "csv_times = [ process_time_string(name.split('_')[0]) for name in os.listdir(processed_data_path)]\n",
    "csv_paths = [name for name in os.listdir(processed_data_path)]\n",
    "# iterate through each csv and find the closest video name\n",
    "video_times = [process_time_string(name.split('_')[0]) for name in os.listdir(video_path)]\n",
    "video_paths = [name for name in os.listdir(video_path)]\n",
    "csv_vid_match = dict()\n",
    "for csv_time in csv_times:\n",
    "    closest_time = video_times[0]\n",
    "    closest_path = video_paths[0]\n",
    "    for i, video_time in enumerate(video_times):\n",
    "        if abs((csv_time - video_time).total_seconds()) <  abs((csv_time - closest_time).total_seconds()):\n",
    "            closest_time = video_time\n",
    "            closest_path = video_paths[i]\n",
    "    total_delta = (csv_time - closest_time).total_seconds()\n",
    "    if total_delta < 10:\n",
    "        csv_vid_match[csv_paths[csv_times.index(csv_time)]] = {\n",
    "            'video_name': closest_path,\n",
    "            'delta_seconds': total_delta\n",
    "        }\n",
    "\n",
    "significant_trials = []\n",
    "for csv_name in csv_vid_match.keys():\n",
    "    df = pd.read_csv(processed_data_path + '/' + csv_name)\n",
    "    if len(df['successful_trials']) >= 10:\n",
    "        significant_trials.append(csv_name)\n",
    "significant_trials.sort()\n",
    "significant_trials.reverse()\n",
    "# randoize order\n",
    "random.shuffle(significant_trials)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate throught each video and load the corresponding video and csv and then display the video \n",
    "\n",
    "for csv_name in significant_trials:\n",
    "    # check if folder for trial exists, if so skip\n",
    "    if os.path.exists('/mnt/teams/Tsuchitori/social_interaction_trials/' + csv_name.split('_')[0] + '/'):\n",
    "        continue\n",
    "    video = cv2.VideoCapture(video_path + csv_vid_match[csv_name]['video_name'])\n",
    "    df = pd.read_csv(processed_data_path + '/' + csv_name)\n",
    "    if len(df['successful_trials']) < 10:\n",
    "        continue\n",
    "    write_successful_trials(video, df, csv_vid_match[csv_name]['delta_seconds'], '/mnt/teams/Tsuchitori/social_interaction_trials/' + csv_name.split('_')[0] + '/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m, new_image)\n\u001b[1;32m     26\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39moriginal\u001b[39m\u001b[39m'\u001b[39m, image)\n\u001b[0;32m---> 28\u001b[0m     \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m12\u001b[39;49m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     29\u001b[0m         \u001b[39mbreak\u001b[39;00m    \n\u001b[1;32m     30\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for test_path in significant_trials:\n",
    "#     test_video = cv2.VideoCapture(video_path + csv_vid_match[test_path]['video_name'])\n",
    "#     test_video = scrub_video_seconds(test_video, 10)\n",
    "#     # get single frame\n",
    "#     success, image = test_video.read()\n",
    "#     # boost contrast\n",
    "#     cv2.imshow('original', image)\n",
    "#     # create slider to adjust contrast\n",
    "#     def nothing(x):\n",
    "#         pass\n",
    "#     # create bars to crop image\n",
    "#     cv2.createTrackbar('x1', 'original', 0, 1000, nothing)\n",
    "#     cv2.createTrackbar('y1', 'original', 0, 1000, nothing)\n",
    "#     cv2.createTrackbar('x2', 'original', 1, 1000, nothing)\n",
    "#     cv2.createTrackbar('y2', 'original', 1, 1000, nothing)\n",
    "#     cv2.setTrackbarPos('x2', 'original', 200)\n",
    "#     cv2.setTrackbarPos('y2', 'original', 200)\n",
    "#     while True:\n",
    "#         # crop newimage \n",
    "#         x1 = cv2.getTrackbarPos('x1', 'original')\n",
    "#         y1 = cv2.getTrackbarPos('y1', 'original')\n",
    "#         x2 = cv2.getTrackbarPos('x2', 'original')\n",
    "#         y2 = cv2.getTrackbarPos('y2', 'original')\n",
    "#         new_image = image[y1:y2, x1:x2]\n",
    "#         cv2.imshow('frame', new_image)\n",
    "#         cv2.imshow('original', image)\n",
    "\n",
    "#         if cv2.waitKey(12) & 0xFF == ord('q'):\n",
    "#             break    \n",
    "#     cv2.destroyAllWindows()\n",
    "#     # save the image to a file\n",
    "#     # display the image\n",
    "#     cv2.imwrite('marker_reference/interaction_area_' + test_path.split('.')[0] + '.jpg', new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
