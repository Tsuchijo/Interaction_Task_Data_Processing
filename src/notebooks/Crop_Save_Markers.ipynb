{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import random\n",
    "import utilities.helper_functions as hf\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = config.remote_video_path\n",
    "processed_data_path = config.successful_trial_path\n",
    "reference_path = [config.marker_path + dir for dir in os.listdir(config.marker_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of video names from the folder of processed CSVs\n",
    "csv_times = [ hf.process_time_string(name.split('_')[0]) for name in os.listdir(processed_data_path)]\n",
    "csv_paths = [name for name in os.listdir(processed_data_path)]\n",
    "# iterate through each csv and find the closest video name\n",
    "video_times = [hf.process_time_string(name.split('_')[0]) for name in os.listdir(video_path)]\n",
    "video_paths = [name for name in os.listdir(video_path)]\n",
    "csv_vid_match = dict()\n",
    "for csv_time in csv_times:\n",
    "    closest_time = video_times[0]\n",
    "    closest_path = video_paths[0]\n",
    "    for i, video_time in enumerate(video_times):\n",
    "        if abs((csv_time - video_time).total_seconds()) <  abs((csv_time - closest_time).total_seconds()):\n",
    "            closest_time = video_time\n",
    "            closest_path = video_paths[i]\n",
    "    total_delta = (csv_time - closest_time).total_seconds()\n",
    "    if total_delta < 10:\n",
    "        csv_vid_match[csv_paths[csv_times.index(csv_time)]] = {\n",
    "            'video_name': closest_path,\n",
    "            'delta_seconds': total_delta\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "significant_trials = []\n",
    "for csv_name in csv_vid_match.keys():\n",
    "    df = pd.read_csv(processed_data_path + '/' + csv_name)\n",
    "    if len(df['successful_trials']) >= 10:\n",
    "        significant_trials.append(csv_name)\n",
    "significant_trials.sort()\n",
    "significant_trials.reverse()\n",
    "# randoize order\n",
    "#random.shuffle(significant_trials)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/murph_4090ws/Documents/Arjun_data/src/notebooks/Crop_Save_Markers.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Arjun_data/src/notebooks/Crop_Save_Markers.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m, new_image)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Arjun_data/src/notebooks/Crop_Save_Markers.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(window_name, image)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Arjun_data/src/notebooks/Crop_Save_Markers.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m1\u001b[39;49m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Arjun_data/src/notebooks/Crop_Save_Markers.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m    \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Arjun_data/src/notebooks/Crop_Save_Markers.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m1\u001b[39m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39ms\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/murph_4090ws/Documents/Arjun_data/src/notebooks/Crop_Save_Markers.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39m# read through 1000 frames of the video\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for test_path in significant_trials:\n",
    "    test_video = cv2.VideoCapture(video_path + csv_vid_match[test_path]['video_name'])\n",
    "    test_video = hf.scrub_video_seconds(test_video, 10)\n",
    "    # get single frame\n",
    "    success, image = test_video.read()\n",
    "    # boost contrast\n",
    "    window_name = test_path.split('/')[-1]\n",
    "    cv2.imshow(window_name, image)\n",
    "    # create slider to adjust contrast\n",
    "    def nothing(x):\n",
    "        pass\n",
    "    # create bars to crop image\n",
    "    cv2.createTrackbar('x1', window_name, 0, 1000, nothing)\n",
    "    cv2.createTrackbar('y1', window_name, 0, 1000, nothing)\n",
    "    cv2.createTrackbar('x2', window_name, 1, 1000, nothing)\n",
    "    cv2.createTrackbar('y2', window_name, 1, 1000, nothing)\n",
    "    cv2.setTrackbarPos('x2', window_name, 200)\n",
    "    cv2.setTrackbarPos('y2', window_name, 200)\n",
    "    while True:\n",
    "        # crop newimage \n",
    "        x1 = cv2.getTrackbarPos('x1', window_name)\n",
    "        y1 = cv2.getTrackbarPos('y1', window_name)\n",
    "        x2 = cv2.getTrackbarPos('x2', window_name)\n",
    "        y2 = cv2.getTrackbarPos('y2', window_name)\n",
    "        new_image = image[y1:y2, x1:x2]\n",
    "        cv2.imshow('frame', new_image)\n",
    "        cv2.imshow(window_name, image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break    \n",
    "        if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "            # read through 1000 frames of the video\n",
    "            for i in range(10000):\n",
    "                success, image = test_video.read()\n",
    "            continue\n",
    "    cv2.destroyAllWindows()\n",
    "    # save the image to a file\n",
    "    # display the image\n",
    "    # check if the image path exists\n",
    "    if not os.path.exists(config.marker_path  + '/interaction_area_' + test_path.split('.')[0] + '.jpg'):\n",
    "        cv2.imwrite(config.marker_path  + '/interaction_area_' + test_path.split('.')[0] + '.jpg', new_image)\n",
    "    else:\n",
    "        cv2.imwrite(config.marker_path  + '/interaction_area_' + test_path.split('.')[0] + str(random.randint(0, 100)) + '.jpg', new_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
