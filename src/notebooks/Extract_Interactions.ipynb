{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import random\n",
    "from utilities.helper_functions import *\n",
    "import config\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports array of videos and names of videos from a folder\n",
    "# @param path: path to folder containing videos\n",
    "# Returns a list of videos and a list of names\n",
    "def load_videos(path):\n",
    "    videos = []\n",
    "    names = []\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith('.mp4'):\n",
    "            names.append(path.split('/')[-1] + file.split('.')[0])\n",
    "            video_capture = cv2.VideoCapture(path + '/' + file)\n",
    "            video = []\n",
    "            while True:\n",
    "                ret, frame = video_capture.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                # convert to grayscale\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                video.append(frame)\n",
    "            videos.append(np.array(video))\n",
    "    return videos, names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_paths = [config.video_output_path + trial for trial in os.listdir(config.video_output_path) ]\n",
    "videos, names = load_videos(video_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take each a video and then subtract each frame from the next frame to get the next movement\n",
    "def calculate_movement(video):\n",
    "    movement = []\n",
    "    for i in range(len(video) - 1):\n",
    "        movement.append(video[i + 1].astype('int16') - video[i].astype('int16'))\n",
    "    return np.abs((np.array(movement) + 256) // 2).astype('uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_movement_frames(video):\n",
    "    movement = []\n",
    "    for i in range(len(video) - 1):\n",
    "        movement.append(np.abs(np.sum(video[i + 1].astype('int16') - video[i].astype('int16'))))\n",
    "    # take a moving average of the movement\n",
    "    try:\n",
    "        movement = np.convolve(movement, np.ones(100) / 100, mode='same')\n",
    "    except (ValueError):\n",
    "        movement = np.zeros(len(movement))\n",
    "    return movement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR:0@1.186] global cap.cpp:643 open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
      "\n",
      "OpenCV(4.8.0) /io/opencv/modules/videoio/src/cap_images.cpp:267: error: (-215:Assertion failed) number < max_number in function 'icvExtractPattern'\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "v cannot be empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m videos, names \u001b[39m=\u001b[39m load_videos(path)\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m video, name \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(videos, names):\n\u001b[0;32m----> 5\u001b[0m     movement \u001b[39m=\u001b[39m extract_movement_frames(video)\n\u001b[1;32m      6\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mmax(movement) \u001b[39m>\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[1;32m      7\u001b[0m         \u001b[39m# find the first frame where the movement is greater than 1000\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         start \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(movement \u001b[39m>\u001b[39m \u001b[39m1000\u001b[39m)[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m, in \u001b[0;36mextract_movement_frames\u001b[0;34m(video)\u001b[0m\n\u001b[1;32m      4\u001b[0m     movement\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mabs(np\u001b[39m.\u001b[39msum(video[i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mint16\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m-\u001b[39m video[i]\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mint16\u001b[39m\u001b[39m'\u001b[39m))))\n\u001b[1;32m      5\u001b[0m \u001b[39m# take a moving average of the movement\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m movement \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconvolve(movement, np\u001b[39m.\u001b[39;49mones(\u001b[39m100\u001b[39;49m) \u001b[39m/\u001b[39;49m \u001b[39m100\u001b[39;49m, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m \u001b[39mreturn\u001b[39;00m movement\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/numeric.py:850\u001b[0m, in \u001b[0;36mconvolve\u001b[0;34m(a, v, mode)\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39ma cannot be empty\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    849\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(v) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 850\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mv cannot be empty\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    851\u001b[0m \u001b[39mreturn\u001b[39;00m multiarray\u001b[39m.\u001b[39mcorrelate(a, v[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], mode)\n",
      "\u001b[0;31mValueError\u001b[0m: v cannot be empty"
     ]
    }
   ],
   "source": [
    "# iterate through all the videos, extract interactions, and then save the video of the interactions to a folder\n",
    "for path in video_paths:\n",
    "    videos, names = load_videos(path)\n",
    "    for video, name in zip(videos, names):\n",
    "        movement = extract_movement_frames(video)\n",
    "        if np.max(movement) > 1000:\n",
    "            # find the first frame where the movement is greater than 1000\n",
    "            start = np.where(movement > 1000)[0][0]\n",
    "            # find the last frame where the movement is greater than 1000\n",
    "            end = np.where(movement > 1000)[0][-1]\n",
    "            movemnent_extracted_video = video[start:end]\n",
    "            # save the video to the movement_extracted folder\n",
    "            helper_functions.save_video(movemnent_extracted_video, config.movement_extracted_output_path + name + '.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_vid = calculate_movement(videos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mVideo\u001b[39m\u001b[39m'\u001b[39m, display_frame)\n\u001b[1;32m     13\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> 14\u001b[0m     \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m12\u001b[39;49m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     15\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     16\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# show vid in a window using opencv\n",
    "for vid in videos:\n",
    "    move_vid = calculate_movement(vid)\n",
    "    i = 0\n",
    "    while not i == len(move_vid):\n",
    "        \n",
    "        # calculate net movement by summing the absolute value of the difference between each frame\n",
    "        net_move = np.sum(move_vid[i].astype(np.int32) - 128)\n",
    "        display_frame = move_vid[i].copy()\n",
    "        # add text to the frame with net move\n",
    "        cv2.putText(display_frame, str(abs(net_move) > 1000), (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        cv2.imshow('Video', display_frame)\n",
    "        i += 1\n",
    "        if cv2.waitKey(12) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
