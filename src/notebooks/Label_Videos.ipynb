{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_657391/738515817.py:16: DeprecationWarning: Please use `curve_fit` from the `scipy.optimize` namespace, the `scipy.optimize.minpack` namespace is deprecated.\n",
      "  from scipy.optimize.minpack import curve_fit\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import random\n",
    "from utilities.helper_functions import helper_functions as hf\n",
    "import config\n",
    "import tdt\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize.minpack import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230818120023_trial_4_start-94_end-748.mp4\n",
      "654\n",
      "25.0\n",
      "94\n",
      "748\n",
      "20230818120023_trial_18_start-41_end-698.mp4\n",
      "657\n",
      "25.0\n",
      "41\n",
      "698\n",
      "20230818120023_trial_4_start-193_end-748.mp4\n",
      "555\n",
      "25.0\n",
      "193\n",
      "748\n",
      "20230814161151_trial_129_start-561_end-709.mp4\n",
      "148\n",
      "25.0\n",
      "561\n",
      "709\n",
      "20230906103144_trial_586_start-120_end-226.mp4\n",
      "106\n",
      "25.0\n",
      "120\n",
      "226\n",
      "20230714161545_trial_9_start-0_end-223.mp4\n",
      "223\n",
      "25.0\n",
      "0\n",
      "223\n",
      "20230822152926_trial_136_start-632_end-748.mp4\n",
      "116\n",
      "25.0\n",
      "632\n",
      "748\n",
      "20230718144045_trial_6_start-0_end-373.mp4\n",
      "373\n",
      "25.0\n",
      "0\n",
      "373\n",
      "20230812150714_trial_12_start-0_end-271.mp4\n",
      "271\n",
      "25.0\n",
      "0\n",
      "271\n",
      "20230905120355_trial_301_start-0_end-748.mp4\n",
      "748\n",
      "25.0\n",
      "0\n",
      "748\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m ret:\n\u001b[1;32m     28\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m, frame)\n\u001b[0;32m---> 29\u001b[0m     k \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m12\u001b[39;49m)\n\u001b[1;32m     30\u001b[0m     \u001b[39mif\u001b[39;00m k \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     31\u001b[0m         label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39minteraction\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Iterate through all videos in the movement_extracted_output_path, then filter for the extracted range and then load and display the video using opencv\n",
    "# Poll the users inputs for 4 possible labels, interaction, f2 only, f1 only or neither, then after save the label to a dictionary and make a csv file\n",
    "for trial in os.listdir(config.movement_extracted_output_path):\n",
    "    path   = config.movement_extracted_output_path + trial + '/'\n",
    "    videos = os.listdir(path)\n",
    "    for video in videos:\n",
    "        if re.match('[0-z]*full_length.mp4', video):\n",
    "            continue\n",
    "        else:\n",
    "            print(video)\n",
    "            cap = cv2.VideoCapture(path + video)\n",
    "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            print(frame_count)\n",
    "            print(fps)\n",
    "            # Get the start and end frame from the video name\n",
    "            start_frame = int(re.search('(?<=start-)\\d*', video).group(0))\n",
    "            end_frame   = int(re.search('(?<=end-)\\d*', video).group(0))\n",
    "            print(start_frame)\n",
    "            print(end_frame)\n",
    "            # Iterate through the video and display each frame\n",
    "            break_flag = False\n",
    "            # create a window to display the video\n",
    "            cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if ret:\n",
    "                    cv2.imshow('frame', frame)\n",
    "                    k = cv2.waitKey(12)\n",
    "                    if k == ord('i'):\n",
    "                        label = 'interaction'\n",
    "                        break\n",
    "                    elif k == ord('f'):\n",
    "                        label = 'f2_only'\n",
    "                        break\n",
    "                    elif k == ord('s'):\n",
    "                        label = 'f1_only'\n",
    "                        break\n",
    "                    elif k == ord('n'):\n",
    "                        label = 'neither'\n",
    "                        break\n",
    "                    elif k == ord('q'):\n",
    "                        cv2.destroyAllWindows()\n",
    "                        break_flag = True\n",
    "                        break\n",
    "                else:\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            cv2.destroyAllWindows()\n",
    "            if break_flag:\n",
    "                break\n",
    "            # Save the label to a dictionary\n",
    "            if 'label_dict' in locals():\n",
    "                label_dict[video] = [label, start_frame, end_frame]\n",
    "            else:\n",
    "                label_dict = {video: label}\n",
    "            # Save the dictionary to a csv file\n",
    "            df = pd.DataFrame.from_dict(label_dict, orient='index', columns=['label'])\n",
    "            df.to_csv(config.movement_labels_path + trial + '.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/murph_4090ws/Documents/Arjun_data/data/movement_labels/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.movement_labels_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
