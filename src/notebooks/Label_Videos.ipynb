{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_524807/738515817.py:16: DeprecationWarning: Please use `curve_fit` from the `scipy.optimize` namespace, the `scipy.optimize.minpack` namespace is deprecated.\n",
      "  from scipy.optimize.minpack import curve_fit\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import random\n",
    "from utilities.helper_functions import helper_functions as hf\n",
    "import config\n",
    "import tdt\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize.minpack import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230818120023_trial_4_start-94_end-748.mp4\n",
      "654\n",
      "25.0\n",
      "94\n",
      "748\n",
      "20230814161151_trial_129_start-561_end-709.mp4\n",
      "148\n",
      "25.0\n",
      "561\n",
      "709\n"
     ]
    }
   ],
   "source": [
    "## Iterate through all videos in the movement_extracted_output_path, then filter for the extracted range and then load and display the video using opencv\n",
    "# Poll the users inputs for 4 possible labels, interaction, f2 only, f1 only or neither, then after save the label to a dictionary and make a csv file\n",
    "for trial in os.listdir(config.movement_extracted_output_path):\n",
    "    path   = config.movement_extracted_output_path + trial + '/'\n",
    "    videos = os.listdir(path)\n",
    "    for video in videos:\n",
    "        if re.match('[0-z]*full_length.mp4', video):\n",
    "            continue\n",
    "        else:\n",
    "            print(video)\n",
    "            cap = cv2.VideoCapture(path + video)\n",
    "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            print(frame_count)\n",
    "            print(fps)\n",
    "            # Get the start and end frame from the video name\n",
    "            start_frame = int(re.search('(?<=start-)\\d*', video).group(0))\n",
    "            end_frame   = int(re.search('(?<=end-)\\d*', video).group(0))\n",
    "            print(start_frame)\n",
    "            print(end_frame)\n",
    "            # Iterate through the video and display each frame\n",
    "            break_flag = False\n",
    "            # create a window to display the video\n",
    "            cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if ret:\n",
    "                    cv2.imshow('frame', frame)\n",
    "                    k = cv2.waitKey(12)\n",
    "                    if k == ord('i'):\n",
    "                        label = 'interaction'\n",
    "                        break\n",
    "                    elif k == ord('f'):\n",
    "                        label = 'f2_only'\n",
    "                        break\n",
    "                    elif k == ord('s'):\n",
    "                        label = 'f1_only'\n",
    "                        break\n",
    "                    elif k == ord('n'):\n",
    "                        label = 'neither'\n",
    "                        break\n",
    "                    elif k == ord('q'):\n",
    "                        cv2.destroyAllWindows()\n",
    "                        break_flag = True\n",
    "                        break\n",
    "                elif not ret:\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "            cv2.destroyAllWindows()\n",
    "            if break_flag:\n",
    "                break\n",
    "            # Save the label to a dictionary\n",
    "            if 'label_dict' in locals():\n",
    "                label_dict[video] = label\n",
    "            else:\n",
    "                label_dict = {video: label}\n",
    "            # Save the dictionary to a csv file\n",
    "            df = pd.DataFrame.from_dict(label_dict, orient='index', columns=['label'])\n",
    "            df.to_csv(config.movement_labels_path + trial + '.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/murph_4090ws/Documents/Arjun_data/data/movement_labels/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.movement_labels_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
